# -*- coding: utf-8 -*-
"""Airflow

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HMv8PVIvC_Q06SK6NNc27oGqO9FIiAAz
"""

# step 1 - import modules
import requests
import json

from airflow import DAG
from datetime import datetime
#import datetime
#from datetime import date
# Operators; we need this to operate!
from airflow.operators.python_operator import PythonOperator


from textblob import TextBlob
import sys
import tweepy
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import nltk
import os
import pycountry
import re
import string
from wordcloud import WordCloud, STOPWORDS
from PIL import Image
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from langdetect import detect
from nltk.stem import SnowballStemmer
from sklearn.feature_extraction.text import CountVectorizer
nltk.download('vader_lexicon')

consumerKey = "ixsBZd13LSsZenY43xyYaKskt"
consumerSecret = "fca3TpfTo5Dpv5QMwOEVhTiQlyPQLBuviXE7f5KF1DCJMOaNRb"
accessToken = "1343698773067911176-1ScI5VoqSL7jiReJYru2WyWmiHbv8Q"
accessTokenSecret = "XTrwCvKn1E488xycJjuvljIFGrPLlnAWsxXvxq1aB5ghT"
auth = tweepy.OAuthHandler(consumerKey, consumerSecret)
auth.set_access_token(accessToken, accessTokenSecret)
api = tweepy.API(auth)


# step 2 - define default args
# These args will get passed on to each operator
# You can override them on a per-task basis during operator initialization
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2020, 1, 6)
    }

df = pd.DataFrame(
     index=['c', 'm'],
     columns = ['Day1_Average','Day1_AverageSoFar','Day1_Time','Day2_Average','Day2_AverageSoFar','Day2_Time','Day3_Average','Day3_AverageSoFar','Day3_Time','Day4_Average','Day4_Time','Day4_AverageSoFar']
)
df.to_csv ("result.csv", index = False, header=True)

# step 3 - instantiate DAG
dag = DAG(
    'airflow-DAG1',
    default_args=default_args,
    description='Tweets analysis',
    schedule_interval='@daily',
)


# step 4 Define tasks

def store_data(**context):
    df = context['task_instance'].xcom_pull(task_ids='CalAverage')
    #df = df.set_index("date_of_interest")
    df.to_csv("data/tweets.csv")

#task 1 to extract the data
def extract_data(**kwargs):
    noOfTweet = 5
    places1 = api.geo_search(query="Malawi", granularity="country")
    place_id1 = places1[0].id
    malawiTweets = tweepy.Cursor(api.search,q="place:%s" % place_id1).items(noOfTweet)
    places2 = api.geo_search(query="Canada", granularity="country")
    place_id2 = places2[0].id
    canada = tweepy.Cursor(api.search,q="place:%s" % place_id2).items(noOfTweet)
    tweetsDF = pd.DataFrame(canada ,columns=['CanadaTweets'])
    tweetsDF['MalawiTweets'] = malawiTweets
    tweetsDF.to_csv ("tweets.csv", index = False, header=True) 
    print("canada Tweets :",canada)
    print(type(canada))
    print("heree",type(str(canada)))
    tweetsArray = [malawiTweets,canada]
    print('tweets :',tweetsArray)
    #df = pd.DataFrame(json.loads(malawiTweets.content))
    #jsonmalawi = json.dumps(malawiTweets)
    #print("Jsonnnnn",type(jsonmalawi))
    #context['ti'].xcom_push(key='tweetsArray',value = malawiTweets)
    #jsoncanada = json.loads(str(canada))
    return canada
    

def sentimentAnalysis(**context):
        tweetsDF= pd.read_csv("tweets.csv")
        tweets =[]
        for index , row in tweetsDF.iterrows():
           tweets.append(row['CanadaTweets'])
        
        tweetsMalawi =[]
        for index , row in tweetsDF.iterrows():
           tweetsMalawi.append(row['MalawiTweets'])          

	#noOfTweet = int(1)
	##Trial
	#tweets , tweets1 = extract_data(**context)
	#tweets= context['ti'].xcom_pull(key='tweetsArray')
	print(context['task_instance'])
	#tweets = context['ti'].xcom_pull(task_ids='extract_data')
	print("Tweettssss",tweets)
	tweets2 = json.dumps(tweets)
	#tweets = context['task_instance'].xcom_pull(task_ids='extract_data')
	print("tweetss",tweets[0])
	print(type(tweets[0]))
	#tweets = json.load(tweets[0])
	#print(type(tweets[0]))
	##Canada
	places = api.geo_search(query="Canada", granularity="country")
	place_id = places[0].id
	print(places)
	#tweets = api.search(q="place:%s" % place_id).items(noOfTweet)
	#tweets = tweepy.Cursor(api.search,q="place:%s" % place_id).items(noOfTweet)
	#tweets = tweepy.Cursor(api.search, q=keyword).items(noOfTweet)
	positive = 0
	negative = 0
	neutral = 0
	polarity = 0
	sumPosCanada =0
	tweet_list = []
	neutral_list = []
	negative_list = []
	positive_list = []
	
	#print(type(canada))
	for tweet in tweets:
	 
	 #print(tweet.text)
	 #if(tweet.place.country == 'Malawi'):
	    print("tweetText :",tweet)
	    #tweet = json.load(tweet)
	    tweet_list.append(tweet.text)
	    print("tweetText :",tweet.text)
	    analysis = TextBlob(tweet.text)
	    score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)
	    neg = score["neg"]
	    neu = score["neu"]
	    pos = score["pos"]
	    comp = score["compound"]
	    polarity += analysis.sentiment.polarity
	    sumPosCanada += pos
	    print(tweet.place.country)
	    #print("neg :",neg)
	    print("pos :",pos)
	    #print("neu :",neu)
	    #print tweet.text + " | " + tweet.place.name if tweet.place else "Undefined place"
	    
	    if neg > pos:
	      negative_list.append(tweet.text)
	      negative += 1
	    elif pos > neg:
	      positive_list.append(tweet.text)
	      positive += 1
	    elif pos == neg:
	      neutral_list.append(tweet.text)
	      neutral += 1



	####Malawi

	places1 = api.geo_search(query="Malawi", granularity="country")
	place1_id = places1[0].id
	print(places1)
	#tweets = api.search(q="place:%s" % place_id).items(noOfTweet)
	#tweets1 = tweepy.Cursor(api.search,q="place:%s" % place1_id).items(noOfTweet)
	#tweets = tweepy.Cursor(api.search, q=keyword).items(noOfTweet)
	positive1 = 0
	negative1= 0
	neutral1 = 0
	polarity1 = 0
	tweet_list1 = []
	neutral_list1 = []
	negative_list1 = []
	positive_list1 = []
	sumPosMalawi =0
	for tweet in tweetsMalawi :
	 
	 #print(tweet.text)
	 #if(tweet.place.country == 'Malawi'):
	    tweet_list1.append(tweet.text)
	    analysis1 = TextBlob(tweet.text)
	    score1 = SentimentIntensityAnalyzer().polarity_scores(tweet.text)
	    neg1 = score1["neg"]
	    neu1 = score1["neu"]
	    pos1 = score1["pos"]
	    comp1 = score1["compound"]
	    polarity1 += analysis1.sentiment.polarity
	    sumPosMalawi += pos1
	    print(tweet.place.country)
	    #print("neg :",neg1)
	    print("pos :",pos1)
	    #print("neu :",neu1)
	    #print tweet.text + " | " + tweet.place.name if tweet.place else "Undefined place"
	    
	    if neg1 > pos1:
	      negative_list1.append(tweet.text)
	      negative1 += 1
	    elif pos1 > neg1:
	      positive_list1.append(tweet.text)
	      positive1 += 1
	    elif pos1 == neg1:
	      neutral_list1.append(tweet.text)
	      neutral1 += 1

        #Saving sum of positive tweets
        sumOfPositiveCanada = [sumPosCanada]
        sumOfPositiveMalawi = [sumPosMalawi]
        sumPositiveDF = pd.DataFrame(sumOfPositiveCanada,columns=['sumPosCanada'])
        sumPositiveDF["sumPosMalawi"] = sumOfPositiveMalawi
        sumPositiveDF.to_csv ("sumPositive.csv", index = False, header=True)

	return sumPosCanada , sumPosMalawi

def CalAverage(**context):
	Day=1
	#sumPosCanada , sumPosMalawi = sentimentAnalysis(**context)
        sumPosDF= pd.read_csv("sumPositive.csv")
        sumPosCanada =sumPosDF.at[0,'sumPosCanada']
        sumPosMalawi =sumPosDF.at[0,'sumPosMalawi']
	averageOfTodayCanada = sumPosCanada/5
	averageOfTodayMalawi = sumPosMalawi/5

	if Day==1:
	  AverageDay2Canada = 0
	  AverageDay3Canada = 0
	  AverageDay4Canada = 0

	  AverageDay2Malawi = 0
	  AverageDay3Malawi = 0
	  AverageDay4Malawi = 0
	  AverageDay1Canada=averageOfTodayCanada
	  AverageDay1Malawi=averageOfTodayMalawi

	  AverageSoFarMalawiDay2 = 0
	  AverageSoFarCanadaDay2 = 0
	  
	  AverageSoFarMalawiDay3 = 0
	  AverageSoFarCanadaDay3 = 0
	  
	  AverageSoFarMalawiDay4 = 0
	  AverageSoFarCanadaDay4 = 0

	  AverageSoFarCanadaDay1 = averageOfTodayCanada
	  AverageSoFarMalawiDay1 = averageOfTodayMalawi

	else:
	  if Day == 2: 
	    AverageDay3Canada = 0
	    AverageDay4Canada = 0

	    AverageDay3Malawi = 0
	    AverageDay4Malawi = 0

	    AverageSoFarMalawiDay3 = 0
	    AverageSoFarCanadaDay3 = 0
	    
	    AverageSoFarMalawiDay4 = 0
	    AverageSoFarCanadaDay4 = 0

	    AverageSoFarCanadaFromcsv = averageOfTodayCanada
	    AverageSoFarMalawiFromcsv = averageOfTodayMalawi
	    AverageDay2Canada = AverageSoFarCanadaFromcsv
	    AverageDay2Malawi = AverageSoFarMalawiFromcsv

	    AverageSoFarCanadaDay2 = (AverageDay1Canada+AverageDay2Canada)/2
	    AverageSoFarMalawiDay2 = (AverageDay1Malawi+AverageDay2Malawi)/2
	    
	    
	  else :
	    if Day == 3:
	      AverageDay4Canada = 0
	      AverageDay4Malawi = 0

	      AverageSoFarMalawiDay4 = 0
	      AverageSoFarCanadaDay4 = 0
	      
	      AverageSoFarCanadaFromcsv = averageOfTodayCanada
	      AverageSoFarMalawiFromcsv = averageOfTodayMalawi
	      AverageDay3Canada = AverageSoFarCanadaFromcsv
	      AverageDay3Malawi = AverageSoFarMalawiFromcsv
	      AverageSoFarCanadaDay3 = (AverageDay1Canada+AverageDay2Canada+AverageDay3Canada)/3
	      AverageSoFarMalawiDay3 = (AverageDay1Malawi+AverageDay2Malawi+AverageDay3Malawi)/3
	      
	      
	    else:
	      if Day == 4 :
	      	AverageSoFarCanadaFromcsv = averageOfTodayCanada
	      	AverageSoFarMalawiFromcsv = averageOfTodayMalawi
	      	AverageDay4Canada = AverageSoFarCanadaFromcsv
	      	AverageDay4Malawi = AverageSoFarMalawiFromcsv
	      	AverageSoFarCanadaDay4 = (AverageDay1Canada+AverageDay2Canada+AverageDay3Canada+AverageDay4Canada)/4
	      	AverageSoFarMalawiDay4 = (AverageDay1Malawi+AverageDay2Malawi+AverageDay3Malawi+AverageDay4Malawi)/4

	#add time to csv
	df.at['c', 'Day'+str(Day)+'_Time'] = datetime.now()
	df.at['m', 'Day'+str(Day)+'_Time'] = datetime.now()
	#add average to csv today's column
	df.at['c', 'Day'+str(1)+'_Average'] = AverageDay1Canada
	df.at['m', 'Day'+str(1)+'_Average'] = AverageDay1Malawi

	df.at['c', 'Day'+str(2)+'_Average'] = AverageDay2Canada
	df.at['m', 'Day'+str(2)+'_Average'] = AverageDay2Malawi

	df.at['c', 'Day'+str(3)+'_Average'] = AverageDay3Canada
	df.at['m', 'Day'+str(3)+'_Average'] = AverageDay3Malawi

	df.at['c', 'Day'+str(4)+'_Average'] = AverageDay4Canada
	df.at['m', 'Day'+str(4)+'_Average'] = AverageDay4Malawi

	#add average so far to csv
	df.at['c', 'Day1_AverageSoFar'] = AverageSoFarCanadaDay1
	df.at['m', 'Day1_AverageSoFar'] = AverageSoFarMalawiDay1

	df.at['c', 'Day2_AverageSoFar'] = AverageSoFarCanadaDay2
	df.at['m', 'Day2_AverageSoFar'] = AverageSoFarMalawiDay2

	df.at['c', 'Day3_AverageSoFar'] = AverageSoFarCanadaDay3
	df.at['m', 'Day3_AverageSoFar'] = AverageSoFarMalawiDay3

	df.at['c', 'Day4_AverageSoFar'] = AverageSoFarCanadaDay4
	df.at['m', 'Day4_AverageSoFar'] = AverageSoFarMalawiDay4
	#save
	df.to_csv ("resultfinal.csv", index = False, header=True)
#task 2 integrating tables

    
    

t1 = PythonOperator(
    task_id='extract_data',
    do_xcom_push = False,
    provide_context=True,
    python_callable=extract_data,
    dag=dag,
)

t2 = PythonOperator(
    task_id='sentimentAnalysis',
    provide_context=True,
    python_callable=sentimentAnalysis,
    dag=dag,
)
t3 =PythonOperator(
    task_id='CalAverage',
    provide_context=True,
    python_callable=CalAverage,
    dag=dag,
)

# step 5 - define dependencies
t1 >> t2 >> t3
'''from datetime import timedelta

# The DAG object; we'll need this to instantiate a DAG
from airflow import DAG

# Operators; we need this to operate!
from airflow.operators.bash import BashOperator
from airflow.utils.dates import days_ago


# These args will get passed on to each operator
# You can override them on a per-task basis during operator initialization
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email': ['airflow@example.com'],
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5)
}
dag = DAG(
	   'ms3',
	   default_args=default_args,
	   description = 'ms3 API',
	   schedule_interval='@once'
)